# Guitar Mentoring with Tactile Sensor

A full-stack application for guitar learning that uses tactile sensors to detect chord fingerings and provides real-time feedback and audio playback.

## Features

- ðŸŽ¸ **Real-time Chord Detection**: Uses tactile sensor data to detect guitar chord fingerings
- ðŸŽµ **Audio Playback**: Plays chord audio files when chords are detected
- ðŸŽ¯ **Practice Mode**: Guided practice sessions with chord-specific exercises
- ðŸ“Š **ML Classification**: Machine learning-based chord classification from sensor data
- ðŸŽ¨ **Modern UI**: React-based frontend with intuitive user interface
- ðŸ”Œ **Sensor Integration**: Ready for tactile sensor hardware integration

## Tech Stack

### Frontend
- **React 19** - UI framework
- **Vite** - Build tool and dev server
- **React Router** - Navigation
- **TypeScript** - Type safety

### Backend
- **FastAPI** - Python web framework
- **NumPy** - Numerical computing
- **Uvicorn** - ASGI server

### Audio
- **Pygame** - Audio playback (for standalone player)

## Project Structure

```
guitar-chords/
â”œâ”€â”€ src/                    # React frontend source
â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”œâ”€â”€ pages/             # Page components (Home, Practice)
â”‚   â”œâ”€â”€ hooks/             # Custom React hooks
â”‚   â”œâ”€â”€ contexts/          # React contexts
â”‚   â””â”€â”€ utils/             # Utility functions (API client)
â”œâ”€â”€ python/                # Python backend
â”‚   â”œâ”€â”€ api/               # FastAPI server
â”‚   â”‚   â””â”€â”€ server.py      # Main API server
â”‚   â”œâ”€â”€ ml/                # Machine learning
â”‚   â”‚   â””â”€â”€ classifier.py   # Chord classification logic
â”‚   â””â”€â”€ sensor/            # Sensor integration
â”‚       â””â”€â”€ reader.py       # Sensor data reader
â”œâ”€â”€ public/                # Static assets
â”‚   â””â”€â”€ sounds/            # Chord audio files
â”œâ”€â”€ player.py              # Standalone audio player
â””â”€â”€ requirements.txt       # Python dependencies
```

## Installation

### Prerequisites
- Node.js (v18 or higher)
- Python 3.8 or higher
- npm or yarn

### Frontend Setup

```bash
# Install Node.js dependencies
npm install
```

### Backend Setup

```bash
# Install Python dependencies
pip install -r python/requirements.txt

# Or install specific packages:
pip install fastapi uvicorn numpy
```

### Audio Player (Optional)

The standalone audio player requires pygame:

```bash
pip install pygame
```

## Running the Application

### Start the Backend Server

```bash
# From the project root
python python/api/server.py
```

The API server will run on `http://127.0.0.1:8000`

### Start the Frontend

In a separate terminal:

```bash
npm run dev
```

The frontend will run on `http://localhost:5173`

### Using the Standalone Audio Player

```bash
python player.py
```

This will open a window where you can press keys to play chords:
- `a` â†’ Am
- `e` â†’ Em
- `g` â†’ G
- `c` â†’ C
- `d` â†’ D
- Press `ESC` to quit

**Note**: Click on the player window to give it focus before pressing keys.

## API Endpoints

### POST `/api/sensor/processed`
Processes sensor data and returns detected chord information.

**Response:**
```json
{
  "chord": "C major",
  "fret_positions": [0, 2, 3],
  "string_positions": [0, 2, 3]
}
```

## Chord Detection

The ML classifier recognizes the following chords:
- **C major**
- **G major**
- **D major**
- **A minor**
- **E minor**

Chord detection is based on binary matrix patterns from the tactile sensor, matching finger positions (string and fret) against predefined chord rules.

## Sound Files

Chord audio files are located in `public/sounds/`:
- `am.mp3` - A minor
- `c.mp3` - C major
- `d.mp3` - D major
- `em.mp3` - E minor
- `g.mp3` - G major

## Development

### Frontend Development

```bash
# Start dev server with hot reload
npm run dev

# Build for production
npm run build

# Preview production build
npm run preview

# Lint code
npm run lint
```

### Backend Development

The FastAPI server includes automatic reloading. Modify `python/api/server.py` and the server will reload automatically.

API documentation is available at `http://127.0.0.1:8000/docs` when the server is running.

### Adding New Chords

1. **Update Classifier**: Add chord rules in `python/ml/classifier.py`:
   ```python
   "New Chord": {
       "string": [0, 1, 2],
       "fret": [0, 2, 3],
   }
   ```

2. **Add Audio File**: Place the MP3 file in `public/sounds/` with the appropriate name (e.g., `newchord.mp3`)

3. **Update Frontend**: Add chord mapping in `src/utils/api.ts` if needed

## Sensor Integration

The sensor reader (`python/sensor/reader.py`) is designed to work with tactile sensor hardware. Currently, it's set up to work with mock data for development.

To integrate real hardware:
1. Install `pyserial`: `pip install pyserial`
2. Configure the serial port in `python/sensor/reader.py`
3. Uncomment and configure the serial connection code

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is open source and available under the MIT License.

## Acknowledgments

- Built with React and FastAPI
- Audio playback powered by Pygame
- Chord detection using pattern matching and ML classification
